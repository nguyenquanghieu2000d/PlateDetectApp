{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import success\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "print(\"import success\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "                        filename  category  \\\n7259  QuangHieuKhongKinh.995.jpg         0   \n7260  QuangHieuKhongKinh.996.jpg         0   \n7261  QuangHieuKhongKinh.997.jpg         0   \n7262  QuangHieuKhongKinh.998.jpg         0   \n7263  QuangHieuKhongKinh.999.jpg         0   \n\n                                             paths  \n7259  ./dataset/dataset\\QuangHieuKhongKinh.995.jpg  \n7260  ./dataset/dataset\\QuangHieuKhongKinh.996.jpg  \n7261  ./dataset/dataset\\QuangHieuKhongKinh.997.jpg  \n7262  ./dataset/dataset\\QuangHieuKhongKinh.998.jpg  \n7263  ./dataset/dataset\\QuangHieuKhongKinh.999.jpg  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>category</th>\n      <th>paths</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>7259</th>\n      <td>QuangHieuKhongKinh.995.jpg</td>\n      <td>0</td>\n      <td>./dataset/dataset\\QuangHieuKhongKinh.995.jpg</td>\n    </tr>\n    <tr>\n      <th>7260</th>\n      <td>QuangHieuKhongKinh.996.jpg</td>\n      <td>0</td>\n      <td>./dataset/dataset\\QuangHieuKhongKinh.996.jpg</td>\n    </tr>\n    <tr>\n      <th>7261</th>\n      <td>QuangHieuKhongKinh.997.jpg</td>\n      <td>0</td>\n      <td>./dataset/dataset\\QuangHieuKhongKinh.997.jpg</td>\n    </tr>\n    <tr>\n      <th>7262</th>\n      <td>QuangHieuKhongKinh.998.jpg</td>\n      <td>0</td>\n      <td>./dataset/dataset\\QuangHieuKhongKinh.998.jpg</td>\n    </tr>\n    <tr>\n      <th>7263</th>\n      <td>QuangHieuKhongKinh.999.jpg</td>\n      <td>0</td>\n      <td>./dataset/dataset\\QuangHieuKhongKinh.999.jpg</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "IMAGE_HEIGHT = 128\n",
    "IMAGE_WIDTH = 128\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "CLASS = dict()\n",
    "CLASS[\"QuangHieuKhongKinh\"] = 0\n",
    "CLASS[\"QuangHieuCoKinh\"] = 1\n",
    "CLASS[\"James Arthur\"] = 2\n",
    "\n",
    "def get_pathframe(path):\n",
    "    \"\"\"\n",
    "    Lấy toàn bộ image và nhãn tương ứng, xong đưa vào pandas dataframe\n",
    "    \"\"\"\n",
    "    filenames = os.listdir(path)\n",
    "    categories = []\n",
    "    paths = []\n",
    "    for filename in filenames:\n",
    "        # paths.append(path+ filename)\n",
    "        paths.append(os.path.join(path, filename))\n",
    "        category = filename.split('.')[0]\n",
    "        categories.append(CLASS[category])\n",
    "\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'filename': filenames,\n",
    "        'category': categories,\n",
    "        'paths': paths\n",
    "    })\n",
    "    return df\n",
    "\n",
    "\n",
    "df = get_pathframe(\"./dataset/dataset\")\n",
    "df.tail(5)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    \"\"\"\n",
    "    Tải từng hình ảnh và chỉnh sửa chúng theo kích thước mong muốn\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMAGE_WIDTH, IMAGE_HEIGHT])\n",
    "    image /= 255.0  # Chuẩn hóa thành phạm vi [0,1]\n",
    "    return image\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def convert_to_tensor(df):\n",
    "    \"\"\"\n",
    "    Chuyển data thành dạng tensor\n",
    "    \"\"\"\n",
    "    path_ds = tf.data.Dataset.from_tensor_slices(df['paths'])\n",
    "    image_ds = path_ds.map(load_and_preprocess_image)\n",
    "    # onehot_label = tf.one_hot(tf.cast(df['category'], tf.int64), 2)  # if using softmax\n",
    "    onehot_label = tf.cast(df['category'], tf.int64)\n",
    "    label_ds = tf.data.Dataset.from_tensor_slices(onehot_label)\n",
    "\n",
    "    return image_ds, label_ds"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'convert_to_tensor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-5-7a40cb9e94b5>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mconvert_to_tensor\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Shape of X in data:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mX\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m\"Shape of Y in data:\"\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m# for i in X.as_numpy_iterator():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'convert_to_tensor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "X, Y = convert_to_tensor(df)\n",
    "print(\"Shape of X in data:\", X)\n",
    "print(\"Shape of Y in data:\", Y)\n",
    "count =0\n",
    "# for i in X.as_numpy_iterator():\n",
    "#     print(i)\n",
    "#     count+=1\n",
    "#     if count == 5:\n",
    "#         break"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-9-fe8e83d4b007>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdata\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mcount\u001B[0m \u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;31m# for i in data.as_numpy_iterator():\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;31m#     print(i)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "data = tf.data.Dataset.zip((X, Y))\n",
    "print(data)\n",
    "count =0\n",
    "# for i in data.as_numpy_iterator():\n",
    "#     print(i)\n",
    "#     count =0\n",
    "#     if count == 5:\n",
    "#         break\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-2-7958cb1e787e>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mdataset\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mDataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mzip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mY\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshuffle\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbuffer_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m6000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mdataset_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtake\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m4000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mdataset_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mskip\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m4000\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[0mdataset_train\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdataset_train\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mBATCH_SIZE\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdrop_remainder\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.zip((X, Y)).shuffle(buffer_size=6000)\n",
    "dataset_train = dataset.take(4000)\n",
    "dataset_test = dataset.skip(4000)\n",
    "\n",
    "dataset_train = dataset_train.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset_test = dataset_test.batch(BATCH_SIZE, drop_remainder=True)\n",
    "\n",
    "count = 0\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# path_ds1 = tf.data.Dataset.from_tensor_slices([1,2,3,4,5])\n",
    "# path_ds2 = tf.data.Dataset.from_tensor_slices([6,7,8,9,10])\n",
    "# path_ds1 = path_ds1.shuffle(buffer_size=5)\n",
    "# path_ds2 = path_ds2.shuffle(buffer_size=5)\n",
    "#\n",
    "# for i in path_ds1.as_numpy_iterator():\n",
    "#     print(i)\n",
    "# print(\"OKOK\")\n",
    "# for i in path_ds2.as_numpy_iterator():\n",
    "#     print(i)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def Mynew_CNNmodel():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(layers.Conv2D(8, (3, 3), padding='same', activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(512, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = tf.keras.optimizers.Adam(0.001)\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',  # loss='categorical_crossentropy' if softmax\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "# model = Mynew_CNNmodel()\n",
    "# model = My_CNNmodel()\n",
    "# model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# hist1 = model.fit_generator(dataset_train, epochs=15, validation_data=dataset_test)\n",
    "# model.save(\"models/my_model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}